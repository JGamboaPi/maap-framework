"use strict";(self.webpackChunkmaap_docs=self.webpackChunkmaap_docs||[]).push([[976],{619:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var t=i(4848),r=i(8453);const o={sidebar_position:1},a="MAAP Chatbot Framework [WIP]",s={id:"intro",title:"MAAP Chatbot Framework [WIP]",description:"Introduction",source:"@site/docs/intro.md",sourceDirName:".",slug:"/intro",permalink:"/maap-chatbot-builder/docs/intro",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",next:{title:"Partners",permalink:"/maap-chatbot-builder/docs/category/partners"}},c={},l=[{value:"Introduction",id:"introduction",level:3},{value:"Reference Architecture Diagram",id:"reference-architecture-diagram",level:3},{value:"Overview of Advanced RAG Approaches",id:"overview-of-advanced-rag-approaches",level:4},{value:"Environment",id:"environment",level:2},{value:"Document Preface",id:"document-preface",level:2},{value:"Steps to run the application",id:"steps-to-run-the-application",level:2},{value:"Installation",id:"installation",level:3},{value:"Configuration",id:"configuration",level:3},{value:"Ingest Data",id:"ingest-data",level:3},{value:"Run the server",id:"run-the-server",level:3},{value:"Start your application UI",id:"start-your-application-ui",level:3}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"maap-chatbot-framework-wip",children:"MAAP Chatbot Framework [WIP]"}),"\n",(0,t.jsx)(n.h3,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.a,{href:"https://www.mongodb.com/services/consulting/ai-applications-program",children:"MongoDB AI Applications Program (MAAP)"})," chatbot framework is a set of libraries that you can use to build your RAG Application\nusing MongoDB and ",(0,t.jsx)(n.a,{href:"https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-overview/",children:"Atlas Vector Search"})," and associated MAAP partners"]}),"\n",(0,t.jsx)(n.p,{children:"The repo offers the flexibility to its user to set up the rag application by simiply configuring a yaml file(details see below). The repo offers the users the flexibilty to choose from various option available through partners program. The following modules of RAG are made configurable"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Data loaders"}),"\n",(0,t.jsx)(n.li,{children:"Embedding Models"}),"\n",(0,t.jsx)(n.li,{children:"Chat LLM Models"}),"\n",(0,t.jsx)(n.li,{children:"Post query Reranker"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"reference-architecture-diagram",children:"Reference Architecture Diagram"}),"\n",(0,t.jsx)(n.p,{children:"Below given is the reference architecture of the framework with various components."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"alt text",src:i(8690).A+"",width:"10818",height:"7638"})}),"\n",(0,t.jsx)(n.h4,{id:"overview-of-advanced-rag-approaches",children:"Overview of Advanced RAG Approaches"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Data Loading"})}),"\n",(0,t.jsx)(n.p,{children:"Applications based on Large Language Models (LLMs) often involve extracting data from databases or files, such as PDFs, and converting it into a format usable by LLMs. The pivotal component here is the data source, containing private knowledge or content obtained."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Data Indexing and Embedding Models: Chunking & Vectorization"})}),"\n",(0,t.jsx)(n.p,{children:"Initially, we construct a vector index to represent the contents of our text documents. This involves breaking down the documents into smaller chunks and converting them into numerical vectors. The vectorized content forms the basis for subsequent retrieval and generation steps."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Post Retrieval: Retrieval, Reranking & Filtering"})}),"\n",(0,t.jsx)(n.p,{children:"After retrieving relevant documents, we refine the context further through reranking and filtering:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Reranking"}),": Prioritizing documents based on relevance."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Filtering"}),": Removing less relevant or noisy documents."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Pre Query Retrieval: Query Transformations"})}),"\n",(0,t.jsx)(n.p,{children:"Advanced RAG models explore various transformations of user queries to enhance retrieval accuracy. Techniques include query expansion and other modifications."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Chat Engine: LLM"})}),"\n",(0,t.jsx)(n.p,{children:"The chat engine combines retrieved context with the user\u2019s query to create a prompt for the language model. This prompt guides the language model in generating contextually relevant responses."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Chat Engine: RAG Agents"})}),"\n",(0,t.jsx)(n.p,{children:"RAG agents manage the entire RAG process, coordinating retrieval, generation, and other components. They ensure seamless interaction between the search index, language model, and other modules."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Prompting: Response Synthesizer"})}),"\n",(0,t.jsx)(n.p,{children:"The response synthesizer generates the actual answer based on the combined context and user query. Attention and prompt engineering mechanisms may be employed to focus on relevant parts of retrieved documents during generation."}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"environment",children:"Environment"}),"\n",(0,t.jsx)(n.p,{children:"The application is tested with below tools."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Node Version :        ",(0,t.jsx)(n.strong,{children:"v20.0+"})]}),"\n",(0,t.jsxs)(n.li,{children:["MongoDB Version (Atlas) :     ",(0,t.jsx)(n.strong,{children:"v7.0"})]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"document-preface",children:"Document Preface"}),"\n",(0,t.jsx)(n.p,{children:"The MongoDB MAAP Chatbot Framework documentation provides a comprehensive guide for setting up a Retrieval-Augmented Generation (RAG) application using MongoDB and Atlas Vector Search, along with integration options for various MAAP partners. This framework is designed to be highly configurable, allowing users to tailor their chatbot applications by simply modifying a YAML configuration file. The framework supports customization in four key areas: data loaders, embedding models, chat LLM (Large Language Models) models, and post-query rerankers."}),"\n",(0,t.jsx)(n.p,{children:"The setup process begins with cloning the project and installing dependencies. This involves navigating to the chatbot directory, building the project locally, and then installing npm packages in the builder/partnerproduct directory."}),"\n",(0,t.jsx)(n.p,{children:"Configuration of the RAG application is crucial and involves specifying details for data ingestion, embedding models, vector storage, and LLM models in a YAML file. This includes settings for data source types (e.g., PDF files), paths, chunk sizes, embedding class names, MongoDB connection strings, database and collection names, and specifics about the vector search index and LLM models."}),"\n",(0,t.jsx)(n.p,{children:"The documentation also highlights the process of instantiating embedding and LLM models based on the configuration. Different classes are instantiated based on the specified class_name in the configuration, catering to various services like VertexAI, Azure-OpenAI, Cohere, and others for embeddings, and a similar approach is taken for LLM models with classes like Fireworks, Anthropic, and Bedrock."}),"\n",(0,t.jsx)(n.p,{children:"Data loaders play a significant role in how data is ingested into the system. The framework supports multiple types of data loaders (e.g., WebLoader, PdfLoader, SitemapLoader, DocxLoader, ConfluenceLoader), each tailored to handle specific data sources like web pages, PDF files, sitemaps, DOCX documents, and Confluence spaces. These loaders are configured with parameters such as source paths and chunking details, and then added to a dataloaders array for processing."}),"\n",(0,t.jsx)(n.p,{children:"After configuring the application, the user is guided through the process of ingesting data, running the server, and starting the UI client application. The UI client application runs locally, allowing users to interact with the chatbot through a web interface."}),"\n",(0,t.jsx)(n.p,{children:"This documentation provides a clear and detailed roadmap for developers to set up and customize their RAG applications using the MongoDB MAAP Chatbot Framework, emphasizing flexibility and ease of use through configuration."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Setup and Running Demo Video: ",(0,t.jsx)(n.a,{href:"https://www.youtube.com/watch?v=-r824BdVZt0",children:"https://www.youtube.com/watch?v=-r824BdVZt0"})]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Internal Chatbot Demo Video: ",(0,t.jsx)(n.a,{href:"https://drive.google.com/file/d/14gcuJLT2BXhQcS-LpjBqvrSY234x7PK9/view?usp=sharing",children:"https://drive.google.com/file/d/14gcuJLT2BXhQcS-LpjBqvrSY234x7PK9/view?usp=sharing"})]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"steps-to-run-the-application",children:"Steps to run the application"}),"\n",(0,t.jsx)(n.h3,{id:"installation",children:"Installation"}),"\n",(0,t.jsx)(n.p,{children:"Clone the project to your machine, and install dependencies."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"cd maap-chabot-builder\nnpm install\ncd builder/partnerproduct\nnpm install\n"})}),"\n",(0,t.jsx)(n.h3,{id:"configuration",children:"Configuration"}),"\n",(0,t.jsxs)(n.p,{children:["Edit the ",(0,t.jsx)(n.code,{children:"config.yaml"})," file to include the necessary details for data ingestion, embedding models, vector storage, and LLM models. The configuration file should include settings for data source types (e.g., PDF files), paths, chunk sizes, embedding class names, MongoDB connection strings, database and collection names, and specifics about the vector search index and LLM models."]}),"\n",(0,t.jsx)(n.p,{children:"For example, the following configuration settings might be included:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"ingest:\n  - source: 'pdf'\n    source_path: '<file_path>'\n    chunk_size: 2000\n    chunk_overlap: 200\nembedding:\n    class_name: Nomic-v1.5\nvector_store:\n    connectionString: '<you_mdb_connection_string>'\n    dbName: '<db_name>'\n    collectionName: 'embedded_content'\n    embeddingKey: 'embedding'\n    textKey: 'text'\n    numCandidates: 150\n    minScore: 0.1 \n    vectorSearchIndexName: 'vector_index'\nllms:\n    class_name: Fireworks\n    model_name: 'accounts/fireworks/models/mixtral-8x22b-instruct'\n    temprature: ''\n    top_p: ''\n    top_k: ''\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Also, please make a copy of the ",(0,t.jsx)(n.code,{children:"examples/partnerproduct/example.env"})," file and rename it as ",(0,t.jsx)(n.code,{children:".env"}),". Place this file in the same folder where you are running your application. In the ",(0,t.jsx)(n.code,{children:".env"})," file, add the necessary API keys, URLs, connection strings, and any other secrets required for your application."]}),"\n",(0,t.jsxs)(n.p,{children:["Go to ",(0,t.jsx)(n.a,{href:"https://mongodb-partners.github.io/maap-chatbot-builder/docs/category/partners",children:"this"})," page for partner specific documentations."]}),"\n",(0,t.jsx)(n.h3,{id:"ingest-data",children:"Ingest Data"}),"\n",(0,t.jsxs)(n.p,{children:["Once configured you can use the yaml file you just created say as in example ",(0,t.jsx)(n.code,{children:"examples/partnerproduct/src/config_1.yaml"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"npm install\nnpm run ingest <path to your config.yaml>\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Go to ",(0,t.jsx)(n.a,{href:"https://mongodb-partners.github.io/maap-chatbot-builder/docs/category/app-modules",children:"this"})," page for loader specific documentations."]}),"\n",(0,t.jsx)(n.h3,{id:"run-the-server",children:"Run the server"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"npm run start <path to your config.yaml>\n"})}),"\n",(0,t.jsx)(n.h3,{id:"start-your-application-ui",children:"Start your application UI"}),"\n",(0,t.jsx)(n.p,{children:"You can start your UI client application by running the following command in a separate terminal."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"cd builder/partnerproduct/ui\nnpm install\nnpm run start\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Your application ui will be running at ",(0,t.jsx)(n.a,{href:"http://localhost:3000",children:"http://localhost:3000"}),"."]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8690:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/RAG_MAAP_2.drawio-f2ffca6597e9f5a2ffa5d2e25f4f03a2.png"},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>s});var t=i(6540);const r={},o=t.createContext(r);function a(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);